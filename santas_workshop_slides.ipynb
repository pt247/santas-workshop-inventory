{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "# Codex & MCP: Sharing for Scalability\n",
        "Santa's Workshop Inventory demo deck\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      },
      "source": [
        "## Goal for this deck\n",
        "- Show how MCP server sharing improves consistency and resource use\n",
        "- Provide runnable cues for the Santa's Workshop Inventory server\n",
        "- Walk through separate vs shared modes you can demo live\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "## Case 1: Separate mode (two servers)\n",
        "- Two HTTP MCP servers: 127.0.0.1:6274 and 127.0.0.1:6275\n",
        "- Elf A client binds to Server A; Elf B client binds to Server B\n",
        "- Duplicate processes, duplicate in-memory inventory state\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      },
      "source": [
        "## Separate mode: runbook\n",
        "```bash\n",
        "source .venv/bin/activate\n",
        "python run_http_server.py --port 6274 --path /mcp  # Server A\n",
        "python run_http_server.py --port 6275 --path /mcp  # Server B\n",
        "```\n",
        "Client config examples:\n",
        "```toml\n",
        "[mcp_servers.\"workshop-elf-a\"]\n",
        "transport = \"http\"\n",
        "url = \"http://127.0.0.1:6274/mcp\"\n",
        "\n",
        "[mcp_servers.\"workshop-elf-b\"]\n",
        "transport = \"http\"\n",
        "url = \"http://127.0.0.1:6275/mcp\"\n",
        "```\n",
        "Prompt cues:\n",
        "- `Hello, I am Elf A. Use the workshop tools to check the current stock of \"Toy Train\".`\n",
        "- `Hello, I am Elf B. Use the workshop tools to check the current stock of \"Toy Train\".`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      },
      "source": [
        "## Separate mode: what you see\n",
        "- Both elves read Toy Train stock: 50\n",
        "- Elf A produces 10 Toy Trains; Server A now reports 60\n",
        "- Elf B re-checks: still 50 (its server never saw the update)\n",
        "- Outcomes: inconsistent data + wasted CPU/RAM from duplicate servers\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "## Case 2: Shared mode (one server)\n",
        "- One HTTP MCP server at 127.0.0.1:6274 serving all clients\n",
        "- Both Elves point to the same URL; inventory state is shared\n",
        "- Less resource use and consistent results for every client\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      },
      "source": [
        "## Shared mode: runbook\n",
        "```bash\n",
        "source .venv/bin/activate\n",
        "python run_http_server.py --port 6274 --path /mcp  # Single shared server\n",
        "```\n",
        "Client config (both Elves share):\n",
        "```toml\n",
        "[mcp_servers.\"santas-workshop-inventory\"]\n",
        "transport = \"http\"\n",
        "url = \"http://127.0.0.1:6274/mcp\"\n",
        "```\n",
        "Prompt cues:\n",
        "- `Elf A reporting in. Use the workshop tools to check the current stock of \"Toy Train\".`\n",
        "- `Elf B reporting in. Use the workshop tools to check the current stock of \"Toy Train\".`\n",
        "- `Produce 5 \"Doll\"s using the produce_toys tool.`\n",
        "- `Produce 10 \"Teddy Bear\"s using the produce_toys tool.`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      },
      "source": [
        "## Shared mode: results\n",
        "- Both elves see Toy Train stock: 60 (single source of truth)\n",
        "- Concurrent production hits the same server:\n",
        "  - Elf A makes 5 Dolls -> stock 205\n",
        "  - Elf B makes 10 Teddy Bears -> stock 110\n",
        "- Outcomes: consistent data, less operational overhead, scalable pattern\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "## Takeaways and talking points\n",
        "- Separate servers isolate context but fragment state and waste resources\n",
        "- A shared MCP server keeps AI clients synchronized and cheaper to run\n",
        "- Reuse this pattern for any tool-heavy workflow that multiple agents need\n",
        "- Demo flow: start servers, run prompts above, call out the contrasting results\n"
      ]
    }
  ],
  "metadata": {
    "celltoolbar": "Slideshow",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
